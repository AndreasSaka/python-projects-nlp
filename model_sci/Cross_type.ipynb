{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross-type.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeKCo_772D7-"
      },
      "source": [
        "!rm -r /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWhm8e6t1AK5"
      },
      "source": [
        "***Cross-type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guPT5rdzy1ls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "19291cfb-4422-47d5-bb55-867f8590dfec"
      },
      "source": [
        "!git clone https://github.com/yuzhimanhua/Multi-BioNER.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Multi-BioNER'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 335 (delta 1), reused 4 (delta 1), pack-reused 327\u001b[K\n",
            "Receiving objects: 100% (335/335), 75.92 MiB | 30.18 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNAik6T1RNN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cecfce8a-0ecf-4711-b7cb-f988b4ea966d"
      },
      "source": [
        "%cd /content/Multi-BioNER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Multi-BioNER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWJ9RUFj1pUP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "11884987-97a4-4615-fc4d-d391ce0d1012"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/e2/57c1a6af4ff0ac095dd68b12bf07771813dbf401faf1b97f5fc0cb963647/numpy-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0MB 201kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.41.1)\n",
            "Collecting torch==0.2.0.post3\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp36-cp36m-manylinux1_x86_64.whl (340.6MB)\n",
            "\u001b[K     |████████████████████████████████| 340.6MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.2.0.post3->-r requirements.txt (line 3)) (3.13)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.3 has requirement numpy>=1.17, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 0.2.0.post3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2020.5.11 has requirement numpy>=1.15.1, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scipy 1.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pywavelets 1.1.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.0.3 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imagecodecs 2020.2.18 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.2.0.post3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0.1.post1 has requirement numpy>=1.16, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, torch\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "Successfully installed numpy-1.13.1 torch-0.2.0.post3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm7bMT3328Ra"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zyuDevR5ecd"
      },
      "source": [
        "!bash run_lm-lstm-crf5.sh #no need"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6JgBUyG8TbY"
      },
      "source": [
        "!python train_wc.py -h #no need"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btx3cTo59DBv"
      },
      "source": [
        "!python seq_wc.py -h #no need"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4wgeih5bont"
      },
      "source": [
        "**Usefull to remember Cross-Type input is Conll2003 format aka Sentences seperated by newline(empty spaces)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJiJ1rZZ_A7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "afaf4f93-1af4-402e-c4e5-edcd60af70a4"
      },
      "source": [
        "!python3 seq_wc.py --load_arg \"/content/Multi-BioNER/checkpoint/cwlm_lstm_crf.json\" --load_check_point \"/content/Multi-BioNER/checkpoint/cwlm_lstm_crf.model\" --input_file \"/content/Multi-BioNER/test.tsv\" --output_file \"/content/Multi-BioNER/annotate/output\" --gpu 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dictionary\n",
            "loading model\n",
            "loading corpus\n",
            "annotating the entity type 0\n",
            "annotating the entity type 1\n",
            "annotating the entity type 2\n",
            "annotating the entity type 3\n",
            "annotating the entity type 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfR8aCJC_xY2"
      },
      "source": [
        "#return '\\n'.join(map(lambda t: t[0] + ' '+ self.r_l_map[t[1].item()], zip(feature, label)))\n",
        "#return '\\n'.join(map(lambda t: t[0] + ' '+ self.r_l_map[t[1].item()], zip(feature, label)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mqi8EQOIdmP"
      },
      "source": [
        "!python3 seq_wc.py --load_arg /content/Multi-BioNER/checkpoint/cwlm_lstm_crf.json --load_check_point /content/Multi-BioNER/checkpoint/cwlm_lstm_crf.model --input_file /content/Multi-BioNER/test.tsv --output_file /content/Multi-BioNER/annotate/output --gpu 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MK9k4H0Uam"
      },
      "source": [
        "!python3 /content/Multi-BioNER/seq_wc.py --load_arg checkpoint/cwlm_lstm_crf.json --load_check_point checkpoint/cwlm_lstm_crf.model --input_file test.tsv --output_file annotate/output --gpu 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqNnqcQ6uVNX"
      },
      "source": [
        "import re\n",
        "\n",
        "with open(\"/content/output.txt\", 'r') as infile, open(\"test.tsv\", 'wt') as outfile:\n",
        "  stripped = [\"\".join(line) for line in infile]\n",
        "  for line in stripped:\n",
        "    words = re.split(r'[` \\-=~!@#$%^&*()_+\\[\\]{};\\'\\\\:\"|<,./<>?\\n]', line)\n",
        "    for word in words:\n",
        "      if word:\n",
        "        outfile.write(word)\n",
        "        outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}